{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('C:/Users/cc/Desktop/Kaggle/Kaggle_feature_encoding/train.csv')\n",
    "test_data = pd.read_csv('C:/Users/cc/Desktop/Kaggle/Kaggle_feature_encoding/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.set_index('id', inplace=True)\n",
    "test_data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ord1 = {'Novice' : 0.0, 'Contributor' : 1.0, 'Expert' : 2.0, 'Master' : 3.0, 'Grandmaster': 4.0}\n",
    "dict_ord3 = {'a': 0.0, 'b': 1.0, 'c': 2.0, 'd': 3.0, 'e': 4.0, 'f': 5.0, 'g': 6.0, 'h': 7.0, \n",
    "        'i': 8.0, 'j': 9.0, 'k': 10.0, 'l': 11.0, 'm': 12.0, 'n': 13.0, 'o': 14.0}\n",
    "dict_ord4 = {'A': 0.0, 'B': 1.0, 'C': 2.0, 'D': 3.0, 'E': 4.0, 'F': 5.0, 'G': 6.0, 'H': 7.0, 'I': 8.0, 'J': 9.0,\n",
    " 'K': 10.0, 'L': 11.0, 'M': 12.0, 'N': 13.0, 'O': 14.0, 'P': 15.0, 'Q': 16.0, 'R': 17.0, 'S': 18.0, 'T': 19.0,\n",
    " 'U': 20.0, 'V': 21.0, 'W': 22.0, 'X': 23.0, 'Y': 24.0, 'Z': 25.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    data['bin_3'] = data['bin_3'].map(lambda x : 1 if x =='T' else 0)\n",
    "    data['bin_4'] = data['bin_4'].map(lambda x : 1 if x =='Y' else 0)    \n",
    "    data['ord_1'] = data['ord_1'].map(dict_ord1)\n",
    "    data['ord_2'] = data['ord_2'].map({'Freezing' : 0.0, 'Cold' : 1.0, 'Warm' : 2.0, 'Hot' : 3.0, 'Boiling Hot' : 4.0, 'Lava Hot' : 5.0})\n",
    "    data['ord_3'] = data['ord_3'].map(dict_ord3)\n",
    "    data['ord_4'] = data['ord_4'].map(dict_ord4)\n",
    "    data = pd.get_dummies(data, columns=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.target_encoder import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_5']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cat = train_data.iloc[:, 10:15].columns.tolist()\n",
    "high_cat.append('ord_5')\n",
    "high_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cc\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "TE_encoder = TargetEncoder()\n",
    "train_te = TE_encoder.fit_transform(train_data[high_cat], train_data['target'])\n",
    "test_te = TE_encoder.transform(test_data[high_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[high_cat] = train_te\n",
    "test_data[high_cat] = test_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocessing(train_data)\n",
    "test_data = preprocessing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 0 to 299999\n",
      "Data columns (total 44 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   bin_0             300000 non-null  int64  \n",
      " 1   bin_1             300000 non-null  int64  \n",
      " 2   bin_2             300000 non-null  int64  \n",
      " 3   bin_3             300000 non-null  int64  \n",
      " 4   bin_4             300000 non-null  int64  \n",
      " 5   nom_5             300000 non-null  float64\n",
      " 6   nom_6             300000 non-null  float64\n",
      " 7   nom_7             300000 non-null  float64\n",
      " 8   nom_8             300000 non-null  float64\n",
      " 9   nom_9             300000 non-null  float64\n",
      " 10  ord_0             300000 non-null  int64  \n",
      " 11  ord_1             300000 non-null  float64\n",
      " 12  ord_2             300000 non-null  float64\n",
      " 13  ord_3             300000 non-null  float64\n",
      " 14  ord_4             300000 non-null  float64\n",
      " 15  ord_5             300000 non-null  float64\n",
      " 16  day               300000 non-null  int64  \n",
      " 17  month             300000 non-null  int64  \n",
      " 18  target            300000 non-null  int64  \n",
      " 19  nom_0_Blue        300000 non-null  uint8  \n",
      " 20  nom_0_Green       300000 non-null  uint8  \n",
      " 21  nom_0_Red         300000 non-null  uint8  \n",
      " 22  nom_1_Circle      300000 non-null  uint8  \n",
      " 23  nom_1_Polygon     300000 non-null  uint8  \n",
      " 24  nom_1_Square      300000 non-null  uint8  \n",
      " 25  nom_1_Star        300000 non-null  uint8  \n",
      " 26  nom_1_Trapezoid   300000 non-null  uint8  \n",
      " 27  nom_1_Triangle    300000 non-null  uint8  \n",
      " 28  nom_2_Axolotl     300000 non-null  uint8  \n",
      " 29  nom_2_Cat         300000 non-null  uint8  \n",
      " 30  nom_2_Dog         300000 non-null  uint8  \n",
      " 31  nom_2_Hamster     300000 non-null  uint8  \n",
      " 32  nom_2_Lion        300000 non-null  uint8  \n",
      " 33  nom_2_Snake       300000 non-null  uint8  \n",
      " 34  nom_3_Canada      300000 non-null  uint8  \n",
      " 35  nom_3_China       300000 non-null  uint8  \n",
      " 36  nom_3_Costa Rica  300000 non-null  uint8  \n",
      " 37  nom_3_Finland     300000 non-null  uint8  \n",
      " 38  nom_3_India       300000 non-null  uint8  \n",
      " 39  nom_3_Russia      300000 non-null  uint8  \n",
      " 40  nom_4_Bassoon     300000 non-null  uint8  \n",
      " 41  nom_4_Oboe        300000 non-null  uint8  \n",
      " 42  nom_4_Piano       300000 non-null  uint8  \n",
      " 43  nom_4_Theremin    300000 non-null  uint8  \n",
      "dtypes: float64(10), int64(9), uint8(25)\n",
      "memory usage: 62.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data['target']\n",
    "X_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin_0               0\n",
       "bin_1               0\n",
       "bin_2               0\n",
       "bin_3               0\n",
       "bin_4               0\n",
       "nom_5               0\n",
       "nom_6               0\n",
       "nom_7               0\n",
       "nom_8               0\n",
       "nom_9               0\n",
       "ord_0               0\n",
       "ord_1               0\n",
       "ord_2               0\n",
       "ord_3               0\n",
       "ord_4               0\n",
       "ord_5               0\n",
       "day                 0\n",
       "month               0\n",
       "nom_0_Blue          0\n",
       "nom_0_Green         0\n",
       "nom_0_Red           0\n",
       "nom_1_Circle        0\n",
       "nom_1_Polygon       0\n",
       "nom_1_Square        0\n",
       "nom_1_Star          0\n",
       "nom_1_Trapezoid     0\n",
       "nom_1_Triangle      0\n",
       "nom_2_Axolotl       0\n",
       "nom_2_Cat           0\n",
       "nom_2_Dog           0\n",
       "nom_2_Hamster       0\n",
       "nom_2_Lion          0\n",
       "nom_2_Snake         0\n",
       "nom_3_Canada        0\n",
       "nom_3_China         0\n",
       "nom_3_Costa Rica    0\n",
       "nom_3_Finland       0\n",
       "nom_3_India         0\n",
       "nom_3_Russia        0\n",
       "nom_4_Bassoon       0\n",
       "nom_4_Oboe          0\n",
       "nom_4_Piano         0\n",
       "nom_4_Theremin      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7802166666666667"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_valid, log_reg.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(log_reg.predict_proba(X_test))\n",
    "result.to_csv('C:/data/result.csv', header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
